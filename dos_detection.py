# -*- coding: utf-8 -*-
"""DoS_detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1e1Irso6jKzj-f4X2CECvyJoAZ5ugqVbi
"""

!pip install kaggle

!mkdir ~/.kaggle

from google.colab import files

files.upload()

!cp kaggle.json ~/.kaggle

!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download mrwellsdavid/unsw-nb15

!unzip unsw-nb15.zip

import pandas as pd
import numpy as np
from numpy import mean,std
import matplotlib.pyplot as plt
import seaborn as sns
plt.style.use('ggplot')

import warnings
warnings.filterwarnings("ignore")

df1 = pd.read_csv("UNSW_NB15_testing-set.csv")
df1.dataframeName = 'wiresharkdata.csv'
nRow,nCol = df1.shape
print(f'There are {nRow} rows and {nCol} columns')

df1.head()

df1.columns

df2 = pd.read_csv("UNSW_NB15_training-set.csv")
df2.dataframeName = 'wiresharkdatatest.csv'
nRow,nCol = df2.shape
print(f'There are {nRow} rows and {nCol} columns')

df2.head()

df1=df1.drop(['id'],axis=1)

df2=df2.drop(['id'],axis=1)

for x in df1.columns:
  print(df1[x].isnull().values.any())

df1

plt.xticks(rotation=90)
sns.countplot(df1['attack_cat'])

df1.drop(df1[(df1['attack_cat'] != 'DoS') & (df1['attack_cat'] != 'Normal')].index, inplace = True)
df2.drop(df2[(df2['attack_cat'] != 'DoS') & (df2['attack_cat'] != 'Normal')].index, inplace = True)

df1

plt.xticks(rotation=90)
sns.countplot(df1['state'])

plt.xticks(rotation=90)
sns.countplot(df1['service'])

from sklearn.preprocessing import LabelEncoder
from sklearn.utils import column_or_1d

class MyLabelEncoder(LabelEncoder):

    def fit(self, y, arr=[]):
        y = column_or_1d(y, warn=True)
        if arr == []:
            arr=y
        self.classes_ = pd.Series(arr).unique()
        return self

le = MyLabelEncoder()

df1.select_dtypes("object").info()

for feature in df1.select_dtypes("object").columns:
    df1[feature]=le.fit_transform(df1[feature])

df1

for feature in df2.select_dtypes("object").columns:
    df2[feature]=le.fit_transform(df2[feature])

df2

pcorr=df1.drop('label',1).corrwith(df1['label'])
plt.figure(figsize=(10,6))
plt.title("Pearson Correlation of Features")
plt.xlabel("Features")
plt.ylabel("Correlation Coeff")
plt.xticks(rotation=90)
plt.bar(pcorr.index, list(map(abs,pcorr.values)))

df1=df1.drop(['dur','proto','service','spkts','sbytes','dinpkt','response_body_len','sloss','sjit','smean','trans_depth','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd'],axis=1)

df2=df2.drop(['dur','proto','service','spkts','sbytes','dinpkt','response_body_len','sloss','sjit','smean','trans_depth','is_ftp_login','ct_ftp_cmd','ct_flw_http_mthd'],axis=1)

pcorr=df1.drop('label',1).corrwith(df1['label'])
plt.figure(figsize=(10,6))
plt.title("Pearson Correlation of Features")
plt.xlabel("Features")
plt.ylabel("Correlation Coeff")
plt.xticks(rotation=90)
plt.bar(pcorr.index, list(map(abs,pcorr.values)))

sns.heatmap(df1.corr().apply(abs))

df1 = df1.drop(['dpkts', 'dloss', 'is_sm_ips_ports', 'tcprtt', 'ackdat', 'ct_srv_src', 'ct_dst_src_ltm', 'swin'], axis=1)

df2 = df2.drop(['dpkts', 'dloss', 'is_sm_ips_ports', 'tcprtt', 'ackdat', 'ct_srv_src', 'ct_dst_src_ltm', 'swin'], axis=1)

sns.heatmap(df1.corr().apply(abs))

df1.info()

y_train=df1['label']
X_train=df1.drop('label',1)

y_test=df2['label']
X_test=df2.drop('label',1)

seed= 42

from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier
from xgboost import XGBClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import GradientBoostingClassifier

models = {
    'LR':LogisticRegression(random_state=seed),
    'RF':RandomForestClassifier(random_state=seed,criterion='entropy'),
    'DT':DecisionTreeClassifier(random_state=seed, criterion='entropy'), 
    'KNN':KNeighborsClassifier(),
    'ET':ExtraTreesClassifier(random_state=seed,criterion="entropy"),
    'XGB':XGBClassifier(random_state=seed),
    'ADA':AdaBoostClassifier(random_state=seed),
    'GB':GradientBoostingClassifier(random_state=seed)
    }

def plot_scores(xval,yval,show_value=False):
    plt.ylim(ymax = max(yval)+0.5, ymin = min(yval)-0.5)
    plt.xticks(rotation=45)
    s = sns.barplot(xval,yval)
    if show_value:
        for x,y in zip(range(len(yval)),yval):
            s.text(x,y+0.1,round(y,2),ha="center")

models =[(key,value) for key,value in models.items()]

print(models)

import time
scores=[]
preds=[]
t=[]
for model in models:
    model[1].fit(X_train,y_train)
    print(model[0],"trained.")
    scores.append(model[1].score(X_test,y_test))
    start_time = time.time()
    preds.append(model[1].predict(X_test))
    t.append((time.time()-start_time)/(y_test.size))
print("Results are ready.")

from sklearn.metrics import confusion_matrix

model_names= [i[0] for i in models]
scores = list(map(lambda x: x*100, scores))

index = 0
#41089
for i in preds:
  print(model_names[index])
  cm = confusion_matrix(y_test, i)
  print(cm)
  p = cm[0][0]/(cm[0][0] + cm[0][1])
  r = cm[0][0]/(cm[0][0] + cm[1][0])
  print("Precision: ", '%.2f'%p)
  print("Recall: ", '%.2f'%r)
  print("F-score:", 2*p*r/(p+r))
  print("Time to predict: ", t[index]*y_test.size)
  print("\n")
  index = index + 1

plot_scores(model_names, scores, True)